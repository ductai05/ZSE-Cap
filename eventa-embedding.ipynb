{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-10T08:36:05.335793Z",
     "iopub.status.busy": "2025-06-10T08:36:05.335572Z",
     "iopub.status.idle": "2025-06-10T08:36:27.670349Z",
     "shell.execute_reply": "2025-06-10T08:36:27.665804Z",
     "shell.execute_reply.started": "2025-06-10T08:36:05.335769Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install ftfy regex tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T08:36:27.672838Z",
     "iopub.status.busy": "2025-06-10T08:36:27.672610Z",
     "iopub.status.idle": "2025-06-10T08:37:00.597650Z",
     "shell.execute_reply": "2025-06-10T08:37:00.591954Z",
     "shell.execute_reply.started": "2025-06-10T08:36:27.672816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch_xla # TPU\n",
    "import torch_xla.core.xla_model as xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T08:38:02.162421Z",
     "iopub.status.busy": "2025-06-10T08:38:02.162019Z",
     "iopub.status.idle": "2025-06-10T08:38:02.174134Z",
     "shell.execute_reply": "2025-06-10T08:38:02.168558Z",
     "shell.execute_reply.started": "2025-06-10T08:38:02.162392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_dir = '/kaggle/input/eventa-img-cieldt/database_images_compressed90'  \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = xm.xla_device()\n",
    "# print(f\"Sử dụng thiết bị: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T08:38:03.617096Z",
     "iopub.status.busy": "2025-06-10T08:38:03.616694Z",
     "iopub.status.idle": "2025-06-10T08:38:08.791439Z",
     "shell.execute_reply": "2025-06-10T08:38:08.785615Z",
     "shell.execute_reply.started": "2025-06-10T08:38:03.617064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filenames = [f for f in os.listdir(image_dir) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "filenames.sort()\n",
    "print('done preparing images path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T08:38:08.793669Z",
     "iopub.status.busy": "2025-06-10T08:38:08.793414Z",
     "iopub.status.idle": "2025-06-10T08:38:42.932608Z",
     "shell.execute_reply": "2025-06-10T08:38:42.928466Z",
     "shell.execute_reply.started": "2025-06-10T08:38:08.793646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T08:41:21.924254Z",
     "iopub.status.busy": "2025-06-10T08:41:21.923891Z",
     "iopub.status.idle": "2025-06-10T08:42:23.744039Z",
     "shell.execute_reply": "2025-06-10T08:42:23.738592Z",
     "shell.execute_reply.started": "2025-06-10T08:41:21.924227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "print('Extracting image features...')\n",
    "all_img_id = []\n",
    "\n",
    "batch_size = 64\n",
    "image_embeddings = []\n",
    "\n",
    "def load_and_preprocess(filename):\n",
    "    try:\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return filename, image\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "total_images_processed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "start = 0\n",
    "end = len(filenames)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    for i in tqdm(range(start, end, batch_size), desc=\"Processing Batches\"):\n",
    "        # print(f\"{i} tasks done\")\n",
    "        batch_filenames = filenames[i: min(i + batch_size, end)]\n",
    "\n",
    "        results = list(executor.map(load_and_preprocess, batch_filenames))\n",
    "\n",
    "        valid_results = [(fn, img) for fn, img in results if img is not None]\n",
    "        if not valid_results:\n",
    "            print(f\"Skipping batch {i}-{i+batch_size} due to no valid images.\")\n",
    "            continue\n",
    "\n",
    "        fnames = [fn for fn, _ in valid_results]\n",
    "        images_list = [img for _, img in valid_results]\n",
    "        \n",
    "        image_tensors = processor(images=images_list, return_tensors=\"pt\")\n",
    "        image_tensors = {k: v.to(device) for k, v in image_tensors.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = model.get_image_features(**image_tensors).cpu().numpy()\n",
    "\n",
    "        for fname, embedding in zip(fnames, embeddings):\n",
    "            img_id = os.path.splitext(fname)[0]\n",
    "            all_img_id.append(img_id)\n",
    "            image_embeddings.append(embedding)\n",
    "\n",
    "        total_images_processed += len(fnames)\n",
    "        # break\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTổng thời gian chạy: {end_time - start_time:.2f} giây\")\n",
    "# Lưu kết quả\n",
    "embeddings_np = np.array(image_embeddings)\n",
    "np.save(\"databse_clip.npy\", embeddings_np)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T08:37:06.838568Z",
     "iopub.status.idle": "2025-06-10T08:37:06.839054Z",
     "shell.execute_reply": "2025-06-10T08:37:06.838740Z",
     "shell.execute_reply.started": "2025-06-10T08:37:06.838727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# query json\n",
    "with open(\"database_clip.json\", \"w\") as f:\n",
    "    json.dump(all_img_id, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T08:37:06.839569Z",
     "iopub.status.idle": "2025-06-10T08:37:06.840025Z",
     "shell.execute_reply": "2025-06-10T08:37:06.839740Z",
     "shell.execute_reply.started": "2025-06-10T08:37:06.839725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "del model\n",
    "del processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SigLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T08:37:06.841129Z",
     "iopub.status.idle": "2025-06-10T08:37:06.841568Z",
     "shell.execute_reply": "2025-06-10T08:37:06.841304Z",
     "shell.execute_reply.started": "2025-06-10T08:37:06.841288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")\n",
    "model = AutoModelForZeroShotImageClassification.from_pretrained(\"google/siglip-so400m-patch14-384\")\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T08:37:06.842235Z",
     "iopub.status.idle": "2025-06-10T08:37:06.842624Z",
     "shell.execute_reply": "2025-06-10T08:37:06.842382Z",
     "shell.execute_reply.started": "2025-06-10T08:37:06.842369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "print('Extracting image features...')\n",
    "all_img_id = []\n",
    "\n",
    "batch_size = 64\n",
    "image_embeddings = []\n",
    "\n",
    "def load_and_preprocess(filename):\n",
    "    try:\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return filename, image\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "total_images_processed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "start = 0\n",
    "end = len(filenames)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    for i in tqdm(range(start, end, batch_size), desc=\"Processing Batches\"):\n",
    "        # print(f\"{i} tasks done\")\n",
    "        batch_filenames = filenames[i: min(i + batch_size, end)]\n",
    "\n",
    "        results = list(executor.map(load_and_preprocess, batch_filenames))\n",
    "\n",
    "        valid_results = [(fn, img) for fn, img in results if img is not None]\n",
    "        if not valid_results:\n",
    "            print(f\"Skipping batch {i}-{i+batch_size} due to no valid images.\")\n",
    "            continue\n",
    "\n",
    "        fnames = [fn for fn, _ in valid_results]\n",
    "        images_list = [img for _, img in valid_results]\n",
    "        \n",
    "        image_tensors = processor(images=images_list, return_tensors=\"pt\")\n",
    "        image_tensors = {k: v.to(device) for k, v in image_tensors.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = model.get_image_features(**image_tensors).cpu().numpy()\n",
    "\n",
    "        for fname, embedding in zip(fnames, embeddings):\n",
    "            img_id = os.path.splitext(fname)[0]\n",
    "            all_img_id.append(img_id)\n",
    "            image_embeddings.append(embedding)\n",
    "\n",
    "        total_images_processed += len(fnames)\n",
    "        # break\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTổng thời gian chạy: {end_time - start_time:.2f} giây\")\n",
    "# Lưu kết quả\n",
    "embeddings_np = np.array(image_embeddings)\n",
    "np.save(\"private_test_siglip.npy\", embeddings_np)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T08:37:06.844553Z",
     "iopub.status.idle": "2025-06-10T08:37:06.844978Z",
     "shell.execute_reply": "2025-06-10T08:37:06.844716Z",
     "shell.execute_reply.started": "2025-06-10T08:37:06.844703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "del processor\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINO V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T08:37:06.845517Z",
     "iopub.status.idle": "2025-06-10T08:37:06.845908Z",
     "shell.execute_reply": "2025-06-10T08:37:06.845666Z",
     "shell.execute_reply.started": "2025-06-10T08:37:06.845653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-giant')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-giant')\n",
    "model.to(device);\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-10T08:37:06.846446Z",
     "iopub.status.idle": "2025-06-10T08:37:06.846833Z",
     "shell.execute_reply": "2025-06-10T08:37:06.846598Z",
     "shell.execute_reply.started": "2025-06-10T08:37:06.846585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "print('Extracting image features...')\n",
    "all_img_id = []\n",
    "\n",
    "batch_size = 64\n",
    "image_embeddings = []\n",
    "\n",
    "def load_and_preprocess(filename):\n",
    "    try:\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return filename, image\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "total_images_processed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "start = 0\n",
    "end = len(filenames)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    for i in tqdm(range(start, end, batch_size), desc=\"Processing Batches\"):\n",
    "        # print(f\"{i} tasks done\")\n",
    "        batch_filenames = filenames[i: min(i + batch_size, end)]\n",
    "\n",
    "        results = list(executor.map(load_and_preprocess, batch_filenames))\n",
    "\n",
    "        valid_results = [(fn, img) for fn, img in results if img is not None]\n",
    "        if not valid_results:\n",
    "            print(f\"Skipping batch {i}-{i+batch_size} due to no valid images.\")\n",
    "            continue\n",
    "\n",
    "        fnames = [fn for fn, _ in valid_results]\n",
    "        images_list = [img for _, img in valid_results]\n",
    "        \n",
    "        image_tensors = processor(images=images_list, return_tensors=\"pt\")\n",
    "        image_tensors = {k: v.to(device) for k, v in image_tensors.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**image_tensors)\n",
    "            embeddings = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        for fname, embedding in zip(fnames, embeddings):\n",
    "            img_id = os.path.splitext(fname)[0]\n",
    "            all_img_id.append(img_id)\n",
    "            image_embeddings.append(embedding)\n",
    "\n",
    "        total_images_processed += len(fnames)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTổng thời gian chạy: {end_time - start_time:.2f} giây\")\n",
    "# Lưu kết quả\n",
    "embeddings_np = np.array(image_embeddings)\n",
    "np.save(\"private_test_dino.npy\", embeddings_np)\n",
    "print('Done .')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 7449685,
     "sourceId": 11855897,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7449575,
     "sourceId": 11856994,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7627381,
     "sourceId": 12114352,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
